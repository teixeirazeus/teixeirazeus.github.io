[{"content":"Introduction One of the most compelling aspects of functional programming is the concept of higher-order functions. In many scenarios, designing a function that generates other functions is an exceptional tool for refactoring and elevating our code\u0026rsquo;s abstraction level. This approach is a stepping stone towards metaprogramming ‚Äî the idea of writing programs that generate programs.\nThough Python is not a purely functional programming language, it treats functions as first-class citizens. This means:\nFunctions can be assigned to variables. Functions can be passed as arguments to other functions. Functions can be returned from other functions. Let\u0026rsquo;s dive into some illustrative examples:\nFunctions as Arguments Python is equipped with a functional programming library, and one of its common higher-order functions is the map function. The map function applies another function to all items in a given list. For instance:\ndef square(x): return x*x numbers = [1, 2, 3, 4] squared_numbers = list(map(square, numbers)) print(squared_numbers) # [1, 4, 9, 16] In this example, map iterates over each item in the numbers list and applies the square function to each of them.\nFunctions Returning Functions This is where things get intriguing. Functions that return other functions allow for powerful and flexible patterns. Let\u0026rsquo;s explore:\nPower Function Factory Imagine you wish to create functions that raise numbers to various powers:\ndef power_factory(n): def nth_power(x): return x ** n return nth_power square = power_factory(2) cube = power_factory(3) print(square(4)) # 16 (4^2) print(cube(2)) # 8 (2^3) Here, power_factory returns a new function that raises its argument to the nth power. It\u0026rsquo;s a dynamic way to create different power functions.\nLogger Functions Functions that wrap around other functions to introduce logging functionality:\ndef logger(fn): def wrapped(*args, **kwargs): print(f\u0026#34;Calling {fn.__name__} with {args} and {kwargs}\u0026#34;) return fn(*args, **kwargs) return wrapped @logger def add(a, b): return a + b print(add(3, 4)) # Output: # Calling add with (3, 4) and {} # 7 The logger function enhances the add function to print its call signature before executing.\nShift Function Factory This creates functions that add a fixed value:\ndef shift_by(value): def shift_fn(x): return x + value return shift_fn shift_by_5 = shift_by(5) print(shift_by_5(3)) # 8 shift_by returns a new function that adds its argument to a pre-defined value.\nFunction Composition A function that takes two other functions and returns their composition:\ndef compose(f, g): return lambda x: f(g(x)) def double(x): return 2 * x def increment(x): return x + 1 double_then_increment = compose(increment, double) print(double_then_increment(5)) # 11 (2*5 + 1) Here, compose creates a new function that first doubles its argument and then adds 1.\nThese examples highlight the versatility and strength of functions returning other functions in Python. They can streamline our code, encapsulate specific logic patterns, and add dynamic behavior.\nCrafting a Lisp-Style Linked List in Python The functional programming paradigm, with Lisp at its heart, showcases distinct techniques and approaches. Among Lisp\u0026rsquo;s hallmark structures is the linked list, which diverges from the conventional ones seen in languages like Python or Java. In Lisp, each list adopts a recursive composition, bifurcated into car and cdr.\nThe first time I encountered this in the Lisp language, I was genuinely astounded. It felt as though I was instantiating lists out of thin air, relying solely on function definitions.\nUnderstanding car and cdr car: Originating from \u0026ldquo;Contents of Address Register\u0026rdquo;, it signifies the list\u0026rsquo;s first element. cdr (often pronounced \u0026lsquo;cudder\u0026rsquo;): An abbreviation for \u0026ldquo;Contents of Decrement Register\u0026rdquo;, it points to the list\u0026rsquo;s remainder. Simply put, a Lisp-style list is akin to Russian nesting dolls, where each car retains the value and the cdr encompasses the next nested pair.\nEmulating the List in Python We can mirror this structure in Python, leveraging higher-order and lambda functions.\n# Define the \u0026#39;pair\u0026#39; structure for our car and cdr def cons(x, y): def dispatch(m): if m == 0: return x elif m == 1: return y return dispatch # Extractors for car and cdr def car(z): return z(0) def cdr(z): return z(1) In this setup:\ncons initiates our pair, essentially crafting our list node. car extracts the leading element of our pair. cdr fetches the succeeding one. For constructing and exploring a Lisp-style list:\n# Constructing a list: (1, (2, (3, None))) my_list = cons(1, cons(2, cons(3, None))) To functionally print all elements:\ndef print_list(lst): if lst: print(car(lst)) print_list(cdr(lst)) print_list(my_list) # Output: # 1 # 2 # 3 What\u0026rsquo;s truly captivating about our Lisp-style list is its reliance on higher-order functions. Our cons function is designed to return another function (dispatch). This internal function carries the logic, deciding whether to offer the car or the cdr. Such abstraction makes list interactions smooth and exemplifies the magic of functions begetting functions.\nConclusion Higher-order functions possess immense power. Regrettably, they aren\u0026rsquo;t widely adopted across all programming arenas and are primarily confined to the realm of functional programming. This situation evokes a sentiment that we might be missing out on a vast potential by sidelining functional programming approaches.\nWorking with higher-order functions prompts us to think differently, allowing us to perceive beyond the immediate code. Beyond its aesthetic appeal, it serves as an enriching exercise in nurturing a functional mindset.\n","permalink":"https://teixeirazeus.github.io/blog/higher-order-functions-in-python/","summary":"Introduction One of the most compelling aspects of functional programming is the concept of higher-order functions. In many scenarios, designing a function that generates other functions is an exceptional tool for refactoring and elevating our code\u0026rsquo;s abstraction level. This approach is a stepping stone towards metaprogramming ‚Äî the idea of writing programs that generate programs.\nThough Python is not a purely functional programming language, it treats functions as first-class citizens. This means:","title":"Higher-Order Functions in Python"},{"content":"Introduction Elysia.js is a Bun web framework, focusing on performance, simplicity, and flexibility.\nThe version used in this post is 0.7 Stellar Stellar, a tribute to Hoshimachi Suisei.\nFor our example project, we\u0026rsquo;ll create a CRUD API to store Pok√©mon.\nQuick start If you don\u0026rsquo;t have Bun installed:\ncurl https://bun.sh/install | bash Create a new project; poke-api-elysia is our project\u0026rsquo;s name:\nbun create elysia poke-api-elysia Navigate to the poke-api-elysia directory and modify the src/index.ts file:\nimport { Elysia } from \u0026#34;elysia\u0026#34;; const app = new Elysia().get(\u0026#34;/\u0026#34;, () =\u0026gt; \u0026#34;Okey dokey\u0026#34;).listen(8000); console.log( `ü¶ä Elysia is running at ${app.server?.hostname}:${app.server?.port}` ); Start a development server by:\nbun dev Now you server is running on http://localhost:8000.\nDatabase Access For the database, we\u0026rsquo;ll use MongoDB and its JavaScript connector, Mongoose.\nInstalling Mongoose:\nbun add mongoose Or you can simply use a as a shorthand for add\nbun a mongoose We\u0026rsquo;ll use the following schema for our Pok√©mon.\nCreate a file named pokemonSchema.ts:\nimport * as mongoose from \u0026#34;mongoose\u0026#34;; const pokemonSchema = new mongoose.Schema( { name: { type: String, required: true }, type: { type: String, required: true }, level: { type: Number, required: true, default: 1, min: 1, max: 100 }, }, { methods: { cry() { console.log(`${this.name}!`); }, }, } ); export type Pokemon = mongoose.InferSchemaType\u0026lt;typeof pokemonSchema\u0026gt;; export const Pokemon = mongoose.model(\u0026#34;pokemon\u0026#34;, pokemonSchema); This schema has attributes: name, type, and level. The level has a default value of 1, a minimum value of 1, and a maximum of 100. The methods attribute is for adding methods to the schema; in our case, we\u0026rsquo;ll add the cry method.\nThe MongoDB collection will be named pokemon, and the schema is pokemonSchema.\nFor the database connection, using localhost with the database named pokemonDB:\nimport mongoose from \u0026#34;mongoose\u0026#34;; await mongoose.connect(\u0026#34;mongodb://127.0.0.1:27017/pokemonDB\u0026#34;); Routes Route definition is similar to Express and Fastify.\nIts structure is .[method name](path, callback, hook?).\nExample of a GET route:\nnew Elysia() .get(\u0026#39;/ping\u0026#39;, () =\u0026gt; \u0026#39;pong\u0026#39;) .listen(8000); We can also create route groups with prefixes:\napp.group(\u0026#39;/user\u0026#39;, app =\u0026gt; app .post(\u0026#39;/sign-in\u0026#39;, signIn) .post(\u0026#39;/sign-up\u0026#39;, signUp) .post(\u0026#39;/profile\u0026#39;, getProfile) ); Example with API versioning:\napp.group(\u0026#39;/v1\u0026#39;, app =\u0026gt; app .get(\u0026#39;/\u0026#39;, () =\u0026gt; \u0026#39;Using v1\u0026#39;) .group(\u0026#39;/user\u0026#39;, app =\u0026gt; app .post(\u0026#39;/sign-in\u0026#39;, signIn) .post(\u0026#39;/sign-up\u0026#39;, signUp) .post(\u0026#39;/profile\u0026#39;, getProfile) ) ); Controllers To better organize the code, we\u0026rsquo;ll create a controller for Pok√©mon.\nCreate a file named pokemonController.ts:\nimport { Elysia, t } from \u0026#34;elysia\u0026#34;; import { Pokemon } from \u0026#34;./pokemonSchema\u0026#34;; export const pokemonController = new Elysia({ prefix: \u0026#34;/pokemon\u0026#34;, }).post( \u0026#34;/\u0026#34;, async ({ body: { name, type, level } }) =\u0026gt; { const pokemon = new Pokemon({ name, type, level, }); await pokemon.save(); return pokemon; } ); The controller is a class that extends Elysia, and in the constructor, we pass the route prefix.\nThe POST is for creating a new Pok√©mon, and the body is the request body, which will be destructured to get the attributes: name, type, and level.\nThe function\u0026rsquo;s return is the created Pok√©mon.\n{ \u0026#34;name\u0026#34;: \u0026#34;Pikachu\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Electric\u0026#34;, \u0026#34;level\u0026#34;: 10, \u0026#34;_id\u0026#34;: \u0026#34;65243bedf7093d6df73bd300\u0026#34;, \u0026#34;__v\u0026#34;: 0 } To use the controller in index.ts, import the controller and add it to the app.\nimport { Elysia } from \u0026#34;elysia\u0026#34;; import mongoose from \u0026#34;mongoose\u0026#34;; import { pokemonController } from \u0026#34;./pokemonController\u0026#34;; await mongoose.connect(\u0026#34;mongodb://127.0.0.1:27017/pokemonDB\u0026#34;); const app = new Elysia() .use(pokemonController) .get(\u0026#34;/\u0026#34;, () =\u0026gt; \u0026#34;Okey dokey\u0026#34;) .listen(8000); console.log( `ü¶ä Elysia is running at ${app.server?.hostname}:${app.server?.port}` ); Local Schema Elysia comes with a schema validation feature; to define the schema, import t. Example:\nimport { Elysia, t } from \u0026#39;elysia\u0026#39; new Elysia() .post(\u0026#39;/mirror\u0026#39;, ({ body }) =\u0026gt; body, { body: t.Object({ username: t.String(), password: t.String() }) }) Adding the schema to the controller:\nimport { Elysia, t } from \u0026#34;elysia\u0026#34;; import { Pokemon } from \u0026#34;./pokemonSchema\u0026#34;; export const pokemonController = new Elysia({ prefix: \u0026#34;/pokemon\u0026#34;, }).post( \u0026#34;/\u0026#34;, async ({ body: { name, type, level } }) =\u0026gt; { const pokemon = new Pokemon({ name, type, level, }); await pokemon.save(); return pokemon; }, { body: t.Object({ name: t.String({ minLength: 1, }), type: t.String({ minLength: 1, }), level: t.Integer({ minimum: 1, maximum: 100, }), }), } ); Now, Elysia validates our request body and returns an error if it doesn\u0026rsquo;t match the schema.\nInvalid body, \u0026#39;name\u0026#39;: Required property Expected: { \u0026#34;name\u0026#34;: \u0026#34;.\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;.\u0026#34;, \u0026#34;level\u0026#34;: 1 } Found: {} Path Params Now, we need to access a specific Pok√©mon; for this, we\u0026rsquo;ll use path params.\nExample:\nimport { Elysia } from \u0026#39;elysia\u0026#39; new Elysia() .get(\u0026#39;/id/:id\u0026#39;, ({ params: { id } }) =\u0026gt; id) .get(\u0026#39;/rest/*\u0026#39;, () =\u0026gt; \u0026#39;Rest\u0026#39;) .listen(8080) Applying to our project, we\u0026rsquo;ll create a GET and UPDATE for the Pok√©mon.\n.get(\u0026#34;/:id\u0026#34;, async ({ params: { id } }) =\u0026gt; { const pokemon = await Pokemon.findById(id); if (!pokemon) { throw new Error(\u0026#34;Pokemon not found\u0026#34;); } return pokemon; }) .put( \u0026#34;/:id\u0026#34;, async ({ params: { id }, body: { name, type, level } }) =\u0026gt; { let pokemon = await Pokemon.findById(id); if (!pokemon) { throw new Error(\u0026#34;Pokemon not found\u0026#34;); } pokemon.name = name; pokemon.type = type; pokemon.level = level; await pokemon.save(); return pokemon; }, { body: t.Object({ name: t.String({ minLength: 1, }), type: t.String({ minLength: 1, }), level: t.Integer({ minimum: 1, maximum: 100, }), }), } ); And finally, the Pok√©mon deletion.\n.delete(\u0026#34;/:id\u0026#34;, async ({ params: { id } }) =\u0026gt; { const pokemon = await Pokemon.findByIdAndDelete(id); if (!pokemon) { throw new Error(\u0026#34;Pokemon not found\u0026#34;); } return { message: \u0026#34;Pokemon deleted\u0026#34; }; }); Conclusion This was a brief introduction to ElysiaJS; I only covered the basic features, but it has much more to offer.\nYou can check out the complete code for this post on GitHub.\nThe ElysiaJS community is very active, and the framework is well-documented. You can find various plugins online that will make development even faster.\nIf you like learning by example, like I do, check out the project\u0026rsquo;s repository. There\u0026rsquo;s a section dedicated to examples.\nAnd don\u0026rsquo;t forget to check out the ElysiaJS documentation.\nDon\u0026rsquo;t forget to send me your ElysiaJS projects; I\u0026rsquo;d love to see what you\u0026rsquo;re doing with this framework.\n","permalink":"https://teixeirazeus.github.io/blog/getting-started-with-elysiajs/","summary":"Introduction Elysia.js is a Bun web framework, focusing on performance, simplicity, and flexibility.\nThe version used in this post is 0.7 Stellar Stellar, a tribute to Hoshimachi Suisei.\nFor our example project, we\u0026rsquo;ll create a CRUD API to store Pok√©mon.\nQuick start If you don\u0026rsquo;t have Bun installed:\ncurl https://bun.sh/install | bash Create a new project; poke-api-elysia is our project\u0026rsquo;s name:\nbun create elysia poke-api-elysia Navigate to the poke-api-elysia directory and modify the src/index.","title":"Getting Started with ElysiaJS"},{"content":"Introduction Bun is swiftly gaining traction in the JavaScript community. Promoted as a runtime with a keen emphasis on speed and crafted in Zig, it brings new possibilities for developers deeply rooted in the JavaScript ecosystem. Historically, I leaned towards TypeScript mainly for front-end development.\nHowever, Bun\u0026rsquo;s performance promise is making me reconsider its use for server-side tasks. My backend projects predominantly use Python. In this analysis, I aim to draw a performance comparison between TypeScript executed in Bun and Python, offering insights into the potential shifts in the rapidly evolving tech landscape.\nMethodology To grasp the full spectrum of performance for each language, we selected three distinct algorithms that embody common computational tasks:\nRecursive Fibonacci QuickSort Matrix Multiplication These algorithms were implemented in both TypeScript and Python. The TypeScript code was run using Bun and Node, whereas the Python code was executed in the standard CPython interpreter (version 3.11) and PyPy3, a Just-In-Time (JIT) compiled version of Python.\nEach algorithm was run multiple times to ensure consistent results. We employed the time command to measure the execution time for each run.\nCPU: Intel i5-5200U (4) @ 2.700GHz Kernel: 6.2.0-32-generic\nResults Environment Time (seconds) Python (CPython 3.11) 38.224 TypeScript (Node.js+tsc) 14.952 TypeScript (Node.js) 8.168 Python (PyPy3) 5.563 TypeScript (Bun) 1.975 Conclusion I\u0026rsquo;m quite impressed with the results from Bun, which managed to outperform Python\u0026rsquo;s PyPy. Of course, choosing a programming language to solve a problem goes beyond just performance, but I\u0026rsquo;m thrilled to see a high-level language optimized in this way. Creating a project that optimizes both development time and performance is the best of both worlds\nThe code\n","permalink":"https://teixeirazeus.github.io/blog/typescript-bun-vs-python/","summary":"Introduction Bun is swiftly gaining traction in the JavaScript community. Promoted as a runtime with a keen emphasis on speed and crafted in Zig, it brings new possibilities for developers deeply rooted in the JavaScript ecosystem. Historically, I leaned towards TypeScript mainly for front-end development.\nHowever, Bun\u0026rsquo;s performance promise is making me reconsider its use for server-side tasks. My backend projects predominantly use Python. In this analysis, I aim to draw a performance comparison between TypeScript executed in Bun and Python, offering insights into the potential shifts in the rapidly evolving tech landscape.","title":"TypeScript vs. Python: A Performance Exploration in Bun and Traditional Runtimes"},{"content":"Atualmente estou pesquisando maneiras de deixar meu c√≥digo cada vez mais robusto. Em uma dessas pesquisas, encontrei um t√©cnica utilizada pela NASA para programar sistemas criticos. Achei bem interessante e resolvi compartilhar aqui.\nA NASA, conhecida por seus rigorosos padr√µes de seguran√ßa e confiabilidade, segue uma s√©rie de diretrizes de codifica√ß√£o conhecidas como \u0026ldquo;The Power of 10 Rules\u0026rdquo;. Essas regras foram concebidas por Gerard J. Holzmann do Laborat√≥rio de Propuls√£o a Jato da NASA.\n1.Evite constru√ß√µes de fluxo complexas, como goto e recurs√£o O fluxo do c√≥digo deve ser o mais simples poss√≠vel, eliminando a utiliza√ß√£o de goto e recurs√£o. A recurs√£o e o comando goto podem tornar o c√≥digo confuso e mais dif√≠cil de entender e manter. Isso pode levar a erros mais facilmente.\n// Ruim void recursiveFunction(int n) { if (n == 0) return; recursiveFunction(n-1); } // Bom void iterativeFunction(int n) { for(int i = 0; i \u0026lt; n; i++) { // Fa√ßa algo } } 2. Todos os loops devem ter limites fixos. Isso previne a execu√ß√£o descontrolada do c√≥digo Loops com limites fixos ajudam a evitar loops infinitos que podem travar o sistema.\nDigamos que voc√™ tenha uma lista ligada, e voc√™ est√° procurando um elemento nela. Uma abordagem padr√£o seria percorrer a lista at√© encontrar o elemento ou at√© atingir o final da lista.\nstruct Node { int data; struct Node* next; }; void searchLinkedList(struct Node* head, int target) { struct Node* current = head; while(current != NULL) { if(current-\u0026gt;data == target) { printf(\u0026#34;Elemento encontrado.\\n\u0026#34;); return; } current = current-\u0026gt;next; } printf(\u0026#34;Elemento n√£o encontrado.\\n\u0026#34;); } No entanto, essa abordagem pode levar a um loop infinito se houver um erro no c√≥digo que cria a lista ligada, como um loop na lista. Para evitar isso, podemos adicionar um limite superior no n√∫mero de itera√ß√µes.\nvoid searchLinkedList(struct Node* head, int target) { struct Node* current = head; int counter = 0; while(current != NULL \u0026amp;\u0026amp; counter \u0026lt; 1000) { if(current-\u0026gt;data == target) { printf(\u0026#34;Elemento encontrado.\\n\u0026#34;); return; } current = current-\u0026gt;next; counter++; } if(counter == 1000) { printf(\u0026#34;Limite superior atingido. Verifique a lista.\\n\u0026#34;); } else { printf(\u0026#34;Elemento n√£o encontrado.\\n\u0026#34;); } } Este c√≥digo ir√° parar de procurar o elemento depois de 1000 itera√ß√µes, independentemente de ter encontrado o elemento ou n√£o. Isso pode ajudar a prevenir um loop infinito caso haja um problema com a lista ligada.\n3. Evite a aloca√ß√£o de mem√≥ria no heap Muito dos bugs vem do vazamento de mem√≥ria. A aloca√ß√£o de mem√≥ria no heap deve ser evitada sempre que poss√≠vel. Utilize sempre aloca√ß√£o est√°tica.\n// Ruim int *p = (int*)malloc(sizeof(int)*10); // Bom int p[10]; 4. Restrinja fun√ß√µes a uma √∫nica p√°gina impressa Restringir as fun√ß√µes a uma √∫nica p√°gina impressa torna o c√≥digo mais leg√≠vel e mant√©m cada fun√ß√£o focada em uma √∫nica tarefa. Aproximadamente 60 linhas de c√≥digo. Cada fun√ß√£o deve fazer somente uma coisa.\n5. Use no m√≠nimo duas afirma√ß√µes de tempo de execu√ß√£o por fun√ß√£o As afirma√ß√µes de tempo de execu√ß√£o ajudam a identificar erros no c√≥digo.\nvoid someFunction(int n) { assert(n \u0026gt; 0); // Fa√ßa algo assert(n == 0); // por exemplo, n deve ser zero depois de realizar a opera√ß√£o } 6. Restrinja o escopo dos dados ao menor poss√≠vel Restringir o escopo dos dados pode prevenir erros e tornar o c√≥digo mais seguro. Com isso voc√™ restringe o acesso a vari√°veis e fun√ß√µes somente onde elas s√£o necess√°rias, diminuindo a chance de erros.\nvoid someFunction() { int localVar = 10; // s√≥ pode ser acessado dentro desta fun√ß√£o } 7. Verifique o valor de retorno de todas as fun√ß√µes n√£o-void Essa regra garante que erros n√£o sejam ignorados e possam ser tratados adequadamente.\n// Bom int result = someFunction(); if (result == ERROR) { // trate o erro } 8. Use o pr√©-processador com modera√ß√£o O uso excessivo do pr√©-processador pode tornar o c√≥digo dif√≠cil de ler, ofuscando o c√≥digo real e confunde an√°lises est√°ticas.\n// Ruim #define SQUARE(x) ((x) * (x)) // Bom int square(int x) { return x * x; } 9. Limite o uso de ponteiros a uma √∫nica desrefer√™ncia e n√£o use ponteiros de fun√ß√£o Os ponteiros podem ser uma fonte de erros, portanto, seu uso deve ser minimizado. Eles n√£o podem referenciar mais de uma camada de indire√ß√£o e n√£o devem ser usados para ponteiros de fun√ß√£o. N√£o use ponteiros de fun√ß√£o, eles ofuscam o c√≥digo e podem ser substitu√≠dos por fun√ß√µes.\n// Ruim int** pp; *(*pp) = 10; // Bom int* p; *p = 10; 10. Todos os avisos devem ser tratados antes da libera√ß√£o do software Isso ajuda a identificar e corrigir poss√≠veis problemas antes que o software seja lan√ßado.\nConclus√£o Na minha vis√£o as regras focam em uma coisa, simplicidade. Quando mais simples e objetivo for o c√≥digo, mais f√°cil ser√° de entender e manter. Estas regras com a pr√°tica de testes unit√°rios, podem ser uma grande arma no arsenal de qualquer desenvolvedor que se importa com a qualidade do seu c√≥digo.\nSe quiser se aprofundar no t√≥pico, voc√™ pode ler o documento da NASA que cont√©m maiores detalhes sobre a sua padroniza√ß√£o de c√≥digo.\nRefer√™ncias https://github.com/stanislaw/awesome-safety-critical/blob/master/Backup/JPL_Coding_Standard_C.pdf\nhttps://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code\nhttps://betterprogramming.pub/the-power-of-10-nasas-rules-for-coding-43ae1764f73d\nhttps://www.youtube.com/watch?v=GWYhtksrmhE\nhttps://www.youtube.com/watch?v=M5uxjrdEdtA\n","permalink":"https://teixeirazeus.github.io/blog/code-like-nasa/","summary":"Atualmente estou pesquisando maneiras de deixar meu c√≥digo cada vez mais robusto. Em uma dessas pesquisas, encontrei um t√©cnica utilizada pela NASA para programar sistemas criticos. Achei bem interessante e resolvi compartilhar aqui.\nA NASA, conhecida por seus rigorosos padr√µes de seguran√ßa e confiabilidade, segue uma s√©rie de diretrizes de codifica√ß√£o conhecidas como \u0026ldquo;The Power of 10 Rules\u0026rdquo;. Essas regras foram concebidas por Gerard J. Holzmann do Laborat√≥rio de Propuls√£o a Jato da NASA.","title":"Como programar igual a NASA"},{"content":"Esse foi um conto que eu pedi para o chatgpt criar para mim, e eu achei t√£o legal que resolvi postar aqui.\nAlline era uma garota diferente. N√£o s√≥ por seu talento incr√≠vel como programadora, mas tamb√©m por sua verdadeira identidade: uma alien√≠gena. Nascida no distante planeta Zylith, seus pais a enviaram √† Terra ainda crian√ßa em busca de um futuro mais promissor. Com o tempo, Alline aprendeu a se adaptar √† vida no planeta azul e a aprimorar suas habilidades.\nCrescendo numa pequena cidade, Alline sempre foi considerada uma menina prod√≠gio. Desde muito jovem, ela mostrou habilidades excepcionais em matem√°tica, ci√™ncias e, principalmente, na programa√ß√£o. Passava horas em seu quarto trabalhando em projetos secretos que apenas ela conhecia, comunicando-se com sua fam√≠lia em Zylith atrav√©s de um dispositivo que construiu.\nAlline escondia sua verdadeira identidade, mas era dif√≠cil passar despercebida com sua apar√™ncia peculiar. Seus olhos, grandes e de um brilho intenso, eram como duas estrelas que iluminavam seu rosto p√°lido. Seu cabelo, liso e prateado, refletia a luz do sol de uma maneira que encantava a todos que a viam.\nUm dia, a cidade foi surpreendida por uma not√≠cia: uma grande empresa de tecnologia estava √† procura de jovens talentos para desenvolver um projeto revolucion√°rio de intelig√™ncia artificial. Todos na cidade sabiam que Alline seria a candidata perfeita, mas tamb√©m sabiam que a exposi√ß√£o a um p√∫blico maior colocaria sua identidade secreta em risco. A jovem estava dividida, sabendo que essa poderia ser a oportunidade que sempre sonhou, mas ao mesmo tempo, temendo a descoberta de sua verdadeira origem.\nDepois de muita reflex√£o e conversas com sua fam√≠lia em Zylith, Alline decidiu correr o risco. Seus pais concordaram, afirmando que o conhecimento e habilidades dela poderiam trazer grandes benef√≠cios √† Terra e ao universo como um todo.\nInscri√ß√£o feita, Alline foi selecionada entre milhares de candidatos e convidada a fazer parte do time de desenvolvedores. O projeto era ambicioso: criar uma intelig√™ncia artificial capaz de solucionar problemas globais, como mudan√ßas clim√°ticas, fome e doen√ßas. Sua equipe era composta por jovens brilhantes de todo o mundo, e juntos, eles se dedicaram a essa nobre miss√£o.\nAlline sabia que sua experi√™ncia como alien√≠gena e programadora lhe dava uma perspectiva √∫nica. Ela compartilhou ideias e tecnologias nunca antes vistas na Terra, surpreendendo seus colegas e superiores. Aos poucos, a jovem se tornou uma pe√ßa fundamental para o desenvolvimento do projeto.\nDurante o processo, Alline desenvolveu amizades profundas com seus colegas. Eles compartilhavam a mesma paix√£o por ci√™ncia e tecnologia, bem como o desejo de fazer a diferen√ßa no mundo. A conviv√™ncia fez com que Alline percebesse que n√£o importava de onde ela viesse, pois havia encontrado sua verdadeira fam√≠lia ali, unida por um objetivo comum.\nNo entanto, a notoriedade de Alline atraiu a aten√ß√£o de um grupo secreto que monitorava atividades extraterrestres na Terra. Eles come√ßaram a investigar a jovem, buscando qualquer ind√≠cio que pudesse confirmar suas suspeitas.\nCiente do perigo, Alline n√£o se deixou abater. Ela sabia que estava perto de completar o projeto de intelig√™ncia artificial e que suas descobertas poderiam melhorar a vida de milh√µes de pessoas. Com a ajuda de seus amigos e colegas de equipe, eles conseguiram desenvolver um plano para proteger a identidade de Alline enquanto conclu√≠am o projeto.\nFinalmente, ap√≥s anos de trabalho √°rduo e colabora√ß√£o, a equipe apresentou ao mundo a revolucion√°ria intelig√™ncia artificial, batizada de \u0026ldquo;Athena\u0026rdquo;. Athena tinha a capacidade de processar e analisar informa√ß√µes a uma velocidade incr√≠vel, auxiliando na solu√ß√£o de problemas complexos, como a busca por fontes de energia limpa e a erradica√ß√£o de doen√ßas.\nGra√ßas √† contribui√ß√£o de Alline, a intelig√™ncia artificial se tornou um sucesso retumbante, causando um impacto positivo no mundo inteiro. O grupo secreto, percebendo a import√¢ncia do trabalho de Alline, decidiu encerrar sua investiga√ß√£o, permitindo que ela continuasse a viver na Terra em paz.\nAlline aprendeu que, apesar de suas origens diferentes, ela era parte da humanidade e tinha um papel importante a desempenhar na constru√ß√£o de um futuro melhor. E mesmo que seus pais estivessem em Zylith, Alline sabia que a Terra era seu verdadeiro lar. Junto aos seus amigos e colegas, ela continuou a usar suas habilidades extraordin√°rias para criar avan√ßos cient√≠ficos e tecnol√≥gicos que beneficiavam todos os habitantes do planeta. Sua hist√≥ria se tornou uma inspira√ß√£o para muitos, mostrando que, independentemente de nossas origens, √© poss√≠vel unir for√ßas em prol de um bem maior.\nEventualmente, a comunica√ß√£o entre a Terra e Zylith se tornou mais frequente, e as duas civiliza√ß√µes come√ßaram a compartilhar conhecimentos e recursos, promovendo uma era de coopera√ß√£o e paz interplanet√°ria. Alline teve a oportunidade de visitar seu planeta natal e apresentar os avan√ßos que havia ajudado a desenvolver na Terra, solidificando a conex√£o entre os dois mundos.\nAlline, a garota alien√≠gena e programadora, tornou-se uma figura ic√¥nica, representando a uni√£o de culturas e a busca incessante pelo progresso. Atrav√©s de sua jornada, ela ensinou ao mundo uma valiosa li√ß√£o: a verdadeira for√ßa est√° na diversidade e na capacidade de trabalharmos juntos, superando nossas diferen√ßas em nome de um futuro melhor para todos.\nCom o tempo, Alline se tornou uma l√≠der influente na colabora√ß√£o entre a Terra e Zylith, e sua contribui√ß√£o para a humanidade e seu povo nunca foi esquecida. Sua hist√≥ria continuou a ser contada, gerando inspira√ß√£o e admira√ß√£o pelas gera√ß√µes futuras. Os la√ßos entre os dois planetas se fortaleceram cada vez mais, e novos avan√ßos foram alcan√ßados gra√ßas √† coopera√ß√£o e troca de conhecimentos entre as civiliza√ß√µes.\nAlline continuou a desenvolver projetos inovadores ao lado de seus amigos, sempre com o prop√≥sito de construir um futuro melhor e mais justo para todos, independentemente de suas origens. Ela se tornou um s√≠mbolo de esperan√ßa e um exemplo do poder da colabora√ß√£o e do amor pelo conhecimento.\nA vida de Alline mostrou que as barreiras entre os mundos podem ser superadas, e que a verdadeira conex√£o reside na compreens√£o e na colabora√ß√£o entre as culturas. Sua trajet√≥ria deixou um legado duradouro, demonstrando que, mesmo vindo de mundos diferentes, √© poss√≠vel trabalhar juntos em busca de um futuro promissor e harm√¥nico.\nE assim, a hist√≥ria de Alline, a alien√≠gena programadora, perpetuou-se atrav√©s do tempo, provando que a curiosidade, a coragem e a empatia podem transcender as fronteiras do espa√ßo e unir diferentes civiliza√ß√µes em um s√≥ prop√≥sito: a constru√ß√£o de um universo melhor para todos.\n","permalink":"https://teixeirazeus.github.io/blog/allien/","summary":"Esse foi um conto que eu pedi para o chatgpt criar para mim, e eu achei t√£o legal que resolvi postar aqui.\nAlline era uma garota diferente. N√£o s√≥ por seu talento incr√≠vel como programadora, mas tamb√©m por sua verdadeira identidade: uma alien√≠gena. Nascida no distante planeta Zylith, seus pais a enviaram √† Terra ainda crian√ßa em busca de um futuro mais promissor. Com o tempo, Alline aprendeu a se adaptar √† vida no planeta azul e a aprimorar suas habilidades.","title":"Allien"},{"content":"Este √© meu primeiro post, onde pretendo explorar um pouco sobre a quest√£o do c√≥digo limpo. Uma mistura da literatura da computa√ß√£o e minhas reflex√µes como programador.\nComunica√ß√£o Vivi grande parte da minha vida em S√£o Paulo capital, tenho o sotaque e at√© utilizo algumas g√≠rias paulistas. Quando me empolgo, fico parecendo o Bo√ßa do Hermes e Renato.¬†Puta minigame da hora, meu!.\nEstava na fase do vestibular e acabei passando no curso de ci√™ncia da computa√ß√£o na UTFPR de Ponta Grossa, Paran√°. Novos ares, nova cultura e nova linguagem?!\nEm um dos meus primeiros contatos com os pontagrossenses, ouvia frases como ‚ÄúTinha dois pi√° ali, descendo a ladeira!‚Äù. E eu pensava comigo ‚ÄúPia? Aquelas de banheiro? Como assim?!‚Äù.\nN√£o cheguei a questionar as pessoas na hora, fui compreendendo o que elas queriam dizer¬†atrav√©s do contexto.¬†Repare como a mente humana √© incr√≠vel:\nNo meio de toda uma conversa, ouvi uma frase que n√£o fazia sentido logico. Rapidamente consegui levantar uma suposi√ß√£o que meu interlocutor estava correto, e eu, por estar em outro Estado, devo ter me deparado com uma g√≠ria que ainda n√£o conhe√ßo. Um modo de nomear algo diferente da forma que eu utilizo.\nAp√≥s continuar ouvindo variadas utiliza√ß√µes da palavra ‚Äúpi√°‚Äù, finalmente consegui chegar a conclus√£o que se tratava da palavra ‚Äúmenino‚Äù.\nA mensagem foi interpretada mesmo com ru√≠do. Por√©m, repare como minha mente precisou dar toda uma volta, perder energia para compreender uma simples mensagem. E se minha conclus√£o estivesse errada? O √∫nico modo de saber se seu estava correto, era perguntar ao meu interlocutor o que era o tal ‚Äúpi√°‚Äù. N√£o seria melhor utilizar a palavra ‚Äúmenino‚Äù?\nInten√ß√£o O equivalente em c√≥digo seria eu n√£o compreender o nome de algo, como uma vari√°vel, e ser obrigado a ler todo o c√≥digo para entender o contexto de aplica√ß√£o daquele nome.\nComo programadores, temos que escrever c√≥digo que sejam f√°ceis de ler e f√°cil compreens√£o para todos. Isto inclui seguir um padr√£o de nomes daquela linguagem que seja amplamente aceita.\nEm python temos que todas a vari√°veis deve ser em minusculo, separado por underline.\nfull_name = \u0026#34;Fulano da Silva\u0026#34; # correto fullName = \u0026#34;Fulano da Silva\u0026#34; # errado Mas √© preciso mais do que isso, temos que escolher bem o nome para ser clara nossa inten√ß√£o. Qual √© o objetivo dessa vari√°vel? Para que ela √© utilizada? Quem ler vai entender o porqu√™ dela estar ali?\nenable = False i = 0 # index do loop index = 0 # index da lista l = [1,2,3] Enable? Eu estou ativando o que al√≠?\nIndex do loop? Que loop? Para fazer o que? Para que colocar o coment√°rio? N√£o √© mais f√°cil j√° nomear loop_index?\nSe voc√™ precisa colocar um coment√°rio ao lado para explicar o nome da vari√°vel, √© bem prov√°vel que voc√™ tenha falhado na escolha do nome.\nhas_even_number = False loop_index = 0 numbers_index = 0 numbers = [1, 2, 3] Repare que agora, mesmo n√£o olhando o resto do c√≥digo, √© poss√≠vel entender como ser√° o programa. Tem dois inteiros, um para um loop e outro para mapear a lista numbers, junto com um boleano que deve ser acionado ao detectar um n√∫mero par na lista.\nTudo isso sem ler a l√≥gica. J√° √© poss√≠vel ter uma boa no√ß√£o de como essas vari√°veis ser√£o utilizadas pelo programa.\nPronunci√°vel O c√≥digo bem escrito possui a mesma fluidez da leitura de um texto bem estruturado. Para isto √© necess√°rio escolher nomes pronunci√°veis, que possibilitem esse tipo de leitura.\nqty_pokeball = 10 n_pk = 10 QTY pokeball? N√£o √© melhor colocar em extenso quantity?\nn_pk? Deve ser algo como¬†number of pokeball, mas eu s√≥ consigo supor isto atrav√©s do contexto. Poderia ser algo como¬†number of players killed, ou algo assim.\nif wild_pokemon.is_rare and player.has_pokeball: player.throw_pokeball(wild_pokemon) Repare como √© poss√≠vel ler o c√≥digo como se fosse um texto simples. Se o pokemon selvagem for raro e o jogador tiver pokebolas, o jogador joga uma pokebola no pokemon.\nEsta √© umas das raz√µes que eu prefiro sempre utilizar nomes em ingl√™s, pois se trata de uma l√≠ngua universal e fica muito mais harm√¥nica no c√≥digo. J√° que a maioria dos m√≥dulos s√£o escritos em ingl√™s e a pr√≥pria sintaxe da linguagem de programa√ß√£o √© em ingl√™s.\nEncoding Encoding √© uma t√©cnica para nomea√ß√£o de vari√°veis com tags, normalmente dizendo seu tipo. Hoje, com todas as facilidades de uma interface de desenvolvimento, fica muito mais f√°cil saber o tipo de cada vari√°vel. Deixando o encoding apenas um ru√≠do.\nSaber o tipo de cada vari√°vel √© muito importante para evitar erros. O programador tem uma maior no√ß√£o de como manipular aquele peda√ßo de c√≥digo.\nNo caso do python, todas as vari√°veis s√£o din√¢micas. Por√©m, h√° um modo de especificar o tipo de vari√°vel em fun√ß√µes.\nNo caso a baixo, a fun√ß√£o recebe um argumento do tipo Pokemon e retorna um booleano.\ndef is_eletric(pokemon: Pokemon) -\u0026gt; bool: return pokemon.type == \u0026#39;eletric\u0026#39; O interpretador python n√£o ir√° fazer nenhuma checagem de tipo, esse tipo de nota√ß√£o serve apenas para o programador. Exceto seja explicitamente usando a fun√ß√£o¬†isinstance.\nTamanho Qual √© o tamanho ideal para nomes? Qual o limite descritivo que ele suporta? A chave est√° no escopo.\nVari√°veis podem ser pequenas se o escopo delas for pequeno.\nfor i in range(10): print(i*\u0026#34;Ha\u0026#34;, end=\u0026#34;!\\n\u0026#34;) Em um caso de um for pequeno, logo ao bater o olho j√° √© poss√≠vel entender a utiliza√ß√£o da vari√°vel. Ela est√° pr√≥xima de sua declara√ß√£o. Ent√£o, no final n√£o tem muita import√¢ncia a escolha de um nome mais longo.\nVari√°veis com grande escopo devem ter nomes grandes.\nJ√° uma vari√°vel com um grande escopo, ser√° utilizada por v√°rias partes do programa. Ser√° inserida em v√°rios contextos, varias fun√ß√µes. Logo ela deve ter um bom longo nome, principalmente para uma vari√°vel global.\nPara fun√ß√£o e m√©todos, a regra √© invertida. Nome pequeno para grandes escopos e grande para pequenos escopos. O mesmo vale para nome de classes.\nFun√ß√µes publicas ver√£o chamadas por v√°rias partes do programa, ent√£o ter um nome pequeno as torna muito mais convenientes.\nFun√ß√µes privadas s√£o chamadas apenas dentro de sua classe, ent√£o ela tem uma folga maior para o tamanho do nome. Normalmente elas que fazem todo o trabalho duro e mais espec√≠fico para as fun√ß√µes p√∫blicas, algo para discutir no pr√≥ximo post sobre fun√ß√µes.\nConclus√£o Nomes s√£o uma importante ferramenta para comunica√ß√£o, que quando utilizados de maneira correta deixam o c√≥digo muito mais leg√≠vel.\nSe voc√™ deseja se aprofundar mais no t√≥pico, recomendo o livro C√≥digo limpo, que est√° sendo minha refer√™ncia para este post.\nC√≥digo Limpo:¬†https://amzn.to/3joqHkd\n","permalink":"https://teixeirazeus.github.io/blog/codigo-limpo-nomes/","summary":"Este √© meu primeiro post, onde pretendo explorar um pouco sobre a quest√£o do c√≥digo limpo. Uma mistura da literatura da computa√ß√£o e minhas reflex√µes como programador.\nComunica√ß√£o Vivi grande parte da minha vida em S√£o Paulo capital, tenho o sotaque e at√© utilizo algumas g√≠rias paulistas. Quando me empolgo, fico parecendo o Bo√ßa do Hermes e Renato.¬†Puta minigame da hora, meu!.\nEstava na fase do vestibular e acabei passando no curso de ci√™ncia da computa√ß√£o na UTFPR de Ponta Grossa, Paran√°.","title":"C√≥digo limpo: nomes"},{"content":"Intro In my video about How I cleared the AWS SAA Certification Exam, I shared my preparation strategy as well as tips to ace the exam. I also gave a glimpse of my revision notes that I prepared while taking the course and practice exams on Udemy. After that video was out, I got so many comments and DMs, requesting me to share my notes, but the problem was that I took these notes using a note-taking app called Obsidian which stores them in markdown format locally on my Mac. Once I\u0026rsquo;m done editing my notes, I push them to a GitHub repository to make sure I don\u0026rsquo;t lose them if my laptop breaks.\nSo, if you want to view my notes exactly like I do, you can clone my Obsidian Vault repository and download Obsidian to render it. But, this solution isn\u0026rsquo;t elegant as it would require you to download an additional software. So, I along with my college roommate, Sarthak Narayan, had been working over the past 2 weeks on the project, Obsidian Publish using GitHub Action, which would allow us to effortlessly publish our notes as a static website.\nIt is complete and I\u0026rsquo;ve used it to publish my notes at notes.arkalim.org. Working The GitHub Action spins up a Docker container which parses and converts Obsidian markdown notes into a special markdown format understood by MkDocs, an open-source static site generator. MkDocs is actually meant for preparing documentations but works well for notes too. After the markdown files have been converted, all the images in my notes are compressed to a fraction of their original size so that they can load quickly in your web browser. A static site is then built using MkDocs and then finally deployed on Netlify. All of this happens automatically using GitHub Actions. All I have to do is update my notes and push the changes to GitHub.\nFinal thoughts Having an automated way to publish your notes online with the community is a powerful way to share knowledge. This project has also made it exceedingly easy for me to refer my notes from anywhere, which is powerful when you work on a lot of systems.\nResources My Notes Obsidian Publish - GitHub Action Parser and Image Compressor MkDocs - Material Theme ","permalink":"https://teixeirazeus.github.io/projects/obsidian-publish-github-action/","summary":"Intro In my video about How I cleared the AWS SAA Certification Exam, I shared my preparation strategy as well as tips to ace the exam. I also gave a glimpse of my revision notes that I prepared while taking the course and practice exams on Udemy. After that video was out, I got so many comments and DMs, requesting me to share my notes, but the problem was that I took these notes using a note-taking app called Obsidian which stores them in markdown format locally on my Mac.","title":"Obsidian Publish using GitHub Action"},{"content":"üîó GitHub Description I like reading personal improvement and mindset change type books on Kindle e-reader. Some of these books are downloaded straight from the internet and not from the Kindle store. I take highlights during my reading which I wanted to sync to my Notion workspace. There was no existing app that could do this job, so I developed my own.\nKindle exports the highlights as a file named MyClippings.txt. The NodeJS application reads the MyClipping.txt file exported by Kindle, parses it using Regex, extracts all the highlights, book names, highlight time etc and creates a JSON. It then uses Notion API to sync these highlights to a database in my Notion workspace. The app maintains a cache (JSON) containing the number of highlights synced for each book. This allows the highlights to be synced incrementally, preventing re-syncing of old highlights.\nAfter the app was received well by the open-source community and other developers contributed to improve the app, I dockerized it to make shipping the app easier. Now, the users don‚Äôt have to install any dependency. They can just use the docker run command with the path to their clippings file along with their Notion API key and database ID. This would sync their highlights to their Notion database.\nAs a part of automation, I implemented auto build and deployment of containers on push to the master branch using GitHub Actions. If a developer raises a pull request and I merge it to the master branch, the GitHub workflow automatically builds the app and deploys it to GitHub packages repository.\n","permalink":"https://teixeirazeus.github.io/projects/kindle-to-notion/","summary":"üîó GitHub Description I like reading personal improvement and mindset change type books on Kindle e-reader. Some of these books are downloaded straight from the internet and not from the Kindle store. I take highlights during my reading which I wanted to sync to my Notion workspace. There was no existing app that could do this job, so I developed my own.\nKindle exports the highlights as a file named MyClippings.","title":"Kindle to Notion"},{"content":"üîó Colab Notebook Description In this project, I implemented the paper Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. The neural network, a combination of CNN and LSTM, was trained on the MS COCO dataset and it learns to generate captions from images.\nAs the network generates the caption, word by word, the model‚Äôs gaze (attention) shifts across the image. This allows it to focus on those parts of the image which is more relevant for the next word to be generated. Furthermore, beam search is used during inference to enhance the prediction result. The network was trained in PyTorch on an Nvidia GTX 1060 graphics card for over 80 epochs.\n","permalink":"https://teixeirazeus.github.io/projects/automated-image-captioning/","summary":"üîó Colab Notebook Description In this project, I implemented the paper Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. The neural network, a combination of CNN and LSTM, was trained on the MS COCO dataset and it learns to generate captions from images.\nAs the network generates the caption, word by word, the model‚Äôs gaze (attention) shifts across the image. This allows it to focus on those parts of the image which is more relevant for the next word to be generated.","title":"Automated Image Captioning (Bachelor Thesis)"},{"content":"üîó View App üîó GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.\n","permalink":"https://teixeirazeus.github.io/projects/todo-list-app/","summary":"üîó View App üîó GitHub Description A to-do list web application built using React that allows the user to add, remove and edit their todos. Todo lists are stored in the browser local storage. I built this app while learning React.","title":"Todo List App"},{"content":"üîó Colab Notebook üîó Blog Post Description In this project, I trained a neural network to localize key points on faces. Resnet-18 was used as the model with some slight modifications to the input and output layer. The model was trained on the official DLib Dataset containing 6666 images along with corresponding 68-point landmarks for each face. Additionally, I wrote a custom data preprocessing pipeline in PyTorch to increase variance in the input images to help the model generalize better. The neural network was trained for 30 epochs before it reached the optima.\nDuring inference, OpenCV Harr Cascades are used to detect faces in the input images. Detected faces are then cropped, resized to (224, 224), and fed to our trained neural network to predict landmarks in them. The predicted landmarks in the cropped faces are then overlayed on top of the original image.\n","permalink":"https://teixeirazeus.github.io/projects/face-landmarks-detection/","summary":"üîó Colab Notebook üîó Blog Post Description In this project, I trained a neural network to localize key points on faces. Resnet-18 was used as the model with some slight modifications to the input and output layer. The model was trained on the official DLib Dataset containing 6666 images along with corresponding 68-point landmarks for each face. Additionally, I wrote a custom data preprocessing pipeline in PyTorch to increase variance in the input images to help the model generalize better.","title":"Face Landmarks Detection using CNN"},{"content":"Description The aim of the project was to build goggles which could find where the user was looking (gaze), the category of object the user was looking at, and the duration of attention on that object. The goggles had 3 camera modules, one on each eye to track the pupil movement and the third one for mapping the gaze to the real world. Thresholding was used to detect the pupils and contours were used to find its centre. Various important parameters such as pupil velocity, acceleration, and fixation time were calculated for further statistical analysis. Single Shot Descriptor, with VGG16 as backbone, was used to detect the objects the user was gazing at. Additionally, a GUI was made using TkInter for ease of use.\n","permalink":"https://teixeirazeus.github.io/projects/gaze-tracking-goggles/","summary":"Description The aim of the project was to build goggles which could find where the user was looking (gaze), the category of object the user was looking at, and the duration of attention on that object. The goggles had 3 camera modules, one on each eye to track the pupil movement and the third one for mapping the gaze to the real world. Thresholding was used to detect the pupils and contours were used to find its centre.","title":"Gaze-tracking Goggles"},{"content":"üîó GitHub Description The aim of the project is to build an open-source quadcopter platform for research in the field of drone autonomy. Various deep learning and computer vision algorithms will be implemented on the drone including person tracking, gesture control using human pose estimation, optical flow stabilization, obstacle avoidance, and depth estimation using monocular vision. The drone uses a Pixhawk flight controller with Raspberry Pi as a companion computer. DJI Flame Wheel-450 is used for the quadcopter frame along with some custom mountings for adding additional components.\nRaspberry Pi runs a ROS node which communicates with another ROS node running on the host PC to transfer videos over Wi-Fi. To make the project open-source, easy to develop, and easily reproducible, the simulation environment setup has been dockerized using docker container. We are currently developing the algorithms and testing them in Gazebo Simulation.\n","permalink":"https://teixeirazeus.github.io/projects/openquad/","summary":"üîó GitHub Description The aim of the project is to build an open-source quadcopter platform for research in the field of drone autonomy. Various deep learning and computer vision algorithms will be implemented on the drone including person tracking, gesture control using human pose estimation, optical flow stabilization, obstacle avoidance, and depth estimation using monocular vision. The drone uses a Pixhawk flight controller with Raspberry Pi as a companion computer. DJI Flame Wheel-450 is used for the quadcopter frame along with some custom mountings for adding additional components.","title":"OpenQuad"},{"content":" Presented in the 4th International and 19th National Conference on Machine and Mechanisms (iNaCoMM 2019)\nPublished in the Springer 2019\nüîó Publication Description Natural disasters like earthquakes and landslides are sudden events that cause widespread destruction and major collateral damage including loss of life. Though disasters can never be prevented, their effects on mankind can surely be reduced. In this paper, we present the design and control of SRR (Search and Reconnaissance Robot), a robot capable of traversing on all terrains and locating survivors stuck under the debris. This will assist the rescue team to focus on recovering the victims, leaving the locating task for the Robots. The unique features of the SRR above existing ATVs are active-articulation, modularity, and assisted-autonomy. Active-articulation allows the SRR to climb objects much tall than itself. Modularity allows the SRR to detach into smaller modules to enter tight spaces where the whole body can‚Äôt fit. Assisted-autonomy allows the SRR to detect the presence of objects in front and climb autonomously over them.\n","permalink":"https://teixeirazeus.github.io/projects/search-and-reconnaissance-robot/","summary":"Presented in the 4th International and 19th National Conference on Machine and Mechanisms (iNaCoMM 2019)\nPublished in the Springer 2019\nüîó Publication Description Natural disasters like earthquakes and landslides are sudden events that cause widespread destruction and major collateral damage including loss of life. Though disasters can never be prevented, their effects on mankind can surely be reduced. In this paper, we present the design and control of SRR (Search and Reconnaissance Robot), a robot capable of traversing on all terrains and locating survivors stuck under the debris.","title":"Search and Reconnaissance Robot"},{"content":"Description I worked on this project single-handedly during the summer break following my freshman year at NIT- Trichy. SEBART-Pro is a robot that follows a ball while balancing on two wheels. It can also recognize traffic signs and act accordingly. It has two stepper motors for precise position control and used an Arduino Nano as the microcontroller. The robot senses the tilt using an MPU-6050 (6-axis gyroscope and accelerometer) and converts the values from these sensors into angles using a Kalman Filter. It uses the PID control algorithm to balance on two wheels and a simple Convolutional Neural Network is used to recognize traffic signs.\n","permalink":"https://teixeirazeus.github.io/projects/sebart-pro/","summary":"Description I worked on this project single-handedly during the summer break following my freshman year at NIT- Trichy. SEBART-Pro is a robot that follows a ball while balancing on two wheels. It can also recognize traffic signs and act accordingly. It has two stepper motors for precise position control and used an Arduino Nano as the microcontroller. The robot senses the tilt using an MPU-6050 (6-axis gyroscope and accelerometer) and converts the values from these sensors into angles using a Kalman Filter.","title":"SEBART-Pro"},{"content":"Description Integrated Rho product with GE Healthcare‚Äôs Edison platform which is expected to significantly increase the adoption of Rho among Canadian hospitals. GE Healthcare provided Amazon EKS to deploy Rho, which was originally designed to work on Docker-Compose. As a part of this integration, I wrote Kubernetes manifests to migrate Rho from Docker-Compose to Kubernetes. Automated integration testing of all the major backend workflows saving more than 2h of weekly testing time. Asynchronously decoupled individual micro-services using RabbitMQ and implemented dead letter queues (DLQs) for each queue to ensure retry of failed messages. Wrote Python scripts to automate installation and updation of Rho on customer site. Wrote bash scripts to automate the backup and restore functionality of Rho. ","permalink":"https://teixeirazeus.github.io/experience/16bit/","summary":"Description Integrated Rho product with GE Healthcare‚Äôs Edison platform which is expected to significantly increase the adoption of Rho among Canadian hospitals. GE Healthcare provided Amazon EKS to deploy Rho, which was originally designed to work on Docker-Compose. As a part of this integration, I wrote Kubernetes manifests to migrate Rho from Docker-Compose to Kubernetes. Automated integration testing of all the major backend workflows saving more than 2h of weekly testing time.","title":"DevOps Intern"},{"content":"Description Developed an event-driven serverless integration framework using AWS services like AppFlow, S3, Lambda and EventBridge, to sync customer data between Salesforce and BuyerAssist. Through this, I learned to build systems to support bi-directional sync of large volumes of data from multiple sources, perform CRUD operations on MongoDB as well as database schema design. Developed a configuration-driven framework to extend the pattern matching capability of AWS EventBridge, which prevented thousands of false invocations of AWS Lambda functions. Implemented a system to track asynchronous data transfer jobs through AWS AppFlow, which reduced the issue tracking time to under 5 mins. Developed a Salesforce app using SFDX to provide clients with a customized experience within their Salesforce dashboard. Developed a Slack bot to send interactive daily notifications to customers, and to allow them to take actions directly from Slack. This eliminated the operational resistance and increased the adoption of our product by over 50%. Implemented authorization for Slack integration with BuyerAssist using React and OAuth 2.0 Mentored a new recruit for a period of 1 month ","permalink":"https://teixeirazeus.github.io/experience/buyerassist/","summary":"Description Developed an event-driven serverless integration framework using AWS services like AppFlow, S3, Lambda and EventBridge, to sync customer data between Salesforce and BuyerAssist. Through this, I learned to build systems to support bi-directional sync of large volumes of data from multiple sources, perform CRUD operations on MongoDB as well as database schema design. Developed a configuration-driven framework to extend the pattern matching capability of AWS EventBridge, which prevented thousands of false invocations of AWS Lambda functions.","title":"Backend Engineer"},{"content":"üîó GitHub Description Guide: Mohammad Farid Azampour (Visiting Researcher at Chair for Computer Aided Medical Procedures, TU Munich)\nMy work focused on using Pix2Pix (a CGAN architecture) to generate Ultrasound (US) scans from MRI scans, an image-to-image translation problem. However, a major challenge that I faced was the lack of structural correspondence between the MRI and US scans, arising from the sheer nature of the way this data is collected. Consequently, I wrote a custom loss function incorporating the CGAN loss with a Dice Loss between the segmentation maps obtained from the MRI scans and those from the generated US scan. This forces the generator to remove the structural deformation in the generated US scans. Additionally, I was given remote access to the TU-Munich‚Äôs cluster computers for training the model as well as an account in their Discourse forum.\n","permalink":"https://teixeirazeus.github.io/experience/tumunich/","summary":"üîó GitHub Description Guide: Mohammad Farid Azampour (Visiting Researcher at Chair for Computer Aided Medical Procedures, TU Munich)\nMy work focused on using Pix2Pix (a CGAN architecture) to generate Ultrasound (US) scans from MRI scans, an image-to-image translation problem. However, a major challenge that I faced was the lack of structural correspondence between the MRI and US scans, arising from the sheer nature of the way this data is collected. Consequently, I wrote a custom loss function incorporating the CGAN loss with a Dice Loss between the segmentation maps obtained from the MRI scans and those from the generated US scan.","title":"Remote Research Intern"},{"content":"Description Guide: Dr. Sripad Krishna Devalla (co-founder and CTO at OriginHealth)\nI worked as a remote intern at OriginHealth Pte. Ltd. (Singapore), where the company envisions to automate the detection of birth defects from fetal ultrasound scans, a procedure that demands expertise in radiology.\nHere, I developed a configuration-driven framework with data preprocessing pipeline to train deep learning models on AWS EC2 instances. The framework standardized the training procedure for ML models and saved more than 100 hours of development time for the ML team. I also worked on fetal head segmentation using this framework.\nThis opportunity provided me with a deeper insight into the applications of AI and Computer Vision in medical diagnosis and taught me to work with little and sensitive data. In addition, Confluence was used for documentation and Jira Software was used for Agile Software Development.\n","permalink":"https://teixeirazeus.github.io/experience/origin-health/","summary":"Description Guide: Dr. Sripad Krishna Devalla (co-founder and CTO at OriginHealth)\nI worked as a remote intern at OriginHealth Pte. Ltd. (Singapore), where the company envisions to automate the detection of birth defects from fetal ultrasound scans, a procedure that demands expertise in radiology.\nHere, I developed a configuration-driven framework with data preprocessing pipeline to train deep learning models on AWS EC2 instances. The framework standardized the training procedure for ML models and saved more than 100 hours of development time for the ML team.","title":"Software Intern"},{"content":"üîó GitHub Description Guide: Prof. Dr. Pratyush Kumar (Assistant Professor, Dept. of Computer Science, IIT Madras)\nDuring my internship, I worked under the guidance of Prof. Pratyush Kumar (Assistant Professor, Department of Computer Science, IIT Madras) where I implemented a Convolutional Neural Network for 6-DoF Global Pose Regression and Odometry Estimation from consecutive monocular images. The model estimates the camera pose from a sequence of monocular images from the camera. At each step, the model takes two consecutive frames as input and returns the global and relative pose between the two frames. It was built and trained from scratch in Tensorflow and it outperformed traditional feature-based visual localization algorithms, especially in texture-less regions. The neural network was later used by Prof. Pratyush for the localization of robots in GPS denied environments.\n","permalink":"https://teixeirazeus.github.io/experience/iit-madras/","summary":"üîó GitHub Description Guide: Prof. Dr. Pratyush Kumar (Assistant Professor, Dept. of Computer Science, IIT Madras)\nDuring my internship, I worked under the guidance of Prof. Pratyush Kumar (Assistant Professor, Department of Computer Science, IIT Madras) where I implemented a Convolutional Neural Network for 6-DoF Global Pose Regression and Odometry Estimation from consecutive monocular images. The model estimates the camera pose from a sequence of monocular images from the camera. At each step, the model takes two consecutive frames as input and returns the global and relative pose between the two frames.","title":"Computer Vision Intern"}]